---
title: "real data analysis experiment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
library(intsurv)
library(survminer)
library(survival)
library(readr)
library(randomForestSRC)
library(ranger)
library(alabama)
library(dplyr)
```

```{r}
lung = read_csv("/Users/fanyiyang/Desktop/Research/Survival\ Tree/real\ data/lung.csv")
tau = max(lung$time)
tau
sum(subset(lung,time<600)$status==1)/nrow(subset(lung,time<600))
nrow(subset(lung,status==0))
```
```{r}
table(lung$status)[2]
```

* Draw the histogram to decide the cut-off point
* Nelson Aalen estimator might make biased prediction at tails
```{r}
set.seed(1)
index = sample(nrow(lung), 100, replace = F)
train = lung[index,]
test = lung[-index,]
hist(lung$time)
```

* Fit the model on train data to obtain the optimal ensemble parameters
```{r}
# Fit random forest model for comparison
structure=TRUE
model1=ranger(Surv(time, status) ~ .,data=train,num.tree=500,mtry=ncol(train)-2,splitrule = "logrank", min.node.size = 5)

set.seed(109) 
# seed 109, num_leaf=4, min leaf size=13
# seed 7305, min leaf size=11

# Fit single survival tree to get initial leaf allocation
model2=ranger(Surv(time, status) ~ .,data=train,num.tree=1,mtry=ncol(train)-2,splitrule = "logrank", min.node.size = 5) 
predict2=predict(model2, data=train)
chf_time=predict2$unique.death.times
chf_value=predict2$chf

leaf <- list() #create a list for the first four CHF curves
leaf[[1]] <- chf_value[1,]
leaf_allocation <- list()
leaf_allocation[[1]] <- c(1)
group=rep(NA,nrow(train)) #create a dictionary to reflect which group each observation is in
group[1]=1

#categorize the initial chf function for each leaf
for (i in 2:nrow(train)) {
  found <- 0
  for (j in 1:length(leaf)) {
    if (all(chf_value[i,] == leaf[[j]])) {
      leaf_allocation[[j]] <- c(leaf_allocation[[j]], i)
      found <- 1
      group[i]=j
    }
  }
  if (found == 0) {
    leaf[[length(leaf) + 1]] <- chf_value[i,]
    leaf_allocation[[length(leaf_allocation) + 1]] <- i
    group[i]=length(leaf_allocation)
  }
}


# We now make sure every leaf has at least 2 observations, otherwise the tree structure might not pertain in 10-fold cross validation. For leaves with 1 or 2 observations, we randomly combine this leaf with another leaf.
leaf_size=as.vector(table(group))
single_leaf=as.vector(which(leaf_size<=2))
normal_leaf=as.vector(which(leaf_size>2))

reassign_dict=as.vector(1:length(leaf))
for (i in 1:length(single_leaf)){
  new_assignment=sample(normal_leaf,1)
  group[which(group==single_leaf[i])]=new_assignment
  reassign_dict[single_leaf[i]]=new_assignment
}

# print(min(table(group)))
# print(table(group))

# change the group from 1 3 4 5 to 1 2 3 4 after combining leaves
num_leaf=length(table(group))
loose_group=as.numeric(names(table(group)))
for (i in 1:length(group)){
  group[i]=which(loose_group==group[i])
}
for (i in 1:length(leaf)){
  reassign_dict[i]=which(loose_group==reassign_dict[i])
}
# print(table(group))

num_leaf=length(table(group))
# print(leaf_allocation)
# print(group)

# keep the first group allocation for CV
first_group=group

#create overall lists of chf function x and y values
chf_value_dict=list(leaf) # a list of lists of chf values
time=list()
for (i in 1:num_leaf){
  time[[i]]=chf_time
}
time_dict=list(time) # a list of lists of time points

# 10-fold cross validation
if (min(table(group))>=2){ # condition automatically fulfilled from the recombining step
  fold=10
  sampleframe = rep(1:fold, ceiling( nrow(train)/fold ) )
  CV_index=sample(sampleframe,nrow(train) ,  replace=FALSE )
  # CV_index=rep(1:10,nrow(train)/10)
  CV_losses=list()
}else{
  fold=nrow(train)
  CV_index=1:nrow(train)
  CV_losses=list()
}

# Store the time, event data for calculating test c index
row_time=c()
row_event=c()
risk_score=list()
for (i in 1:num_leaf){
  risk_score[[i]]=c(0)
}

for (step in 1:fold){
  CV_test=train[CV_index==step,]
  CV_train=train[CV_index!=step,]
  group=first_group[CV_index!=step] # if 10-fold, drop 10 elements in group
  test_group=first_group[CV_index==step]
  if (length(table(group))!=num_leaf){
    structure=FALSE
    break
  }
  #For each validation fold, we update the estimator in each leaf using the data from this leaf specifically.
  first_chf=list()
  first_time=list()
  for (i in 1:num_leaf){
    result_combined=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(CV_train,group==i))
    chf=result_combined$cumhaz
    first_chf[[i]]=chf
    time=result_combined$time
    first_time[[i]]=time
  }
  chf_value_dict[[1]]=first_chf
  time_dict[[1]]=first_time
  
  predict2=predict(model2, data=CV_train)
  # chf_time=predict2$unique.death.times
  # chf_value=predict2$chf
  
  train_set=cbind(CV_train,group)
  # Perform the log-rank test
  
  result=tryCatch( # some time only event or only non-event, cannot do pairwise log rank
    expr={
      pairwise_survdiff(Surv(time, status)~group, data=train_set)
    },
    error = function(e) {
      message("There was an error message.") # prints structure of exception
      return(list(NULL))
    }
  )
  
  if (length(result)==1){
    structure=FALSE
    break
  }
  result=pairwise_survdiff(Surv(time, status)~group, data=train_set)
  
  pvalue=result$p.value
  index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
  row=as.integer(rownames(pvalue)[index[1,1]])
  col=as.integer(colnames(pvalue)[index[1,2]]) #row and col are index of the leaves to be combined
  
  result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))
  
  chf_value_combined_2=result_combined_2$cumhaz
  chf_time_combined_2=result_combined_2$time
  
  dict=as.vector(1:num_leaf) # store the process of combining leaves
  group_dict=list(dict)
  
  if (num_leaf>1){
    for (i in 2:(num_leaf)){
      #record the current chf function value and time
      chf=chf_value_dict[[i-1]]
      time=time_dict[[i-1]]
      for (j in 1:num_leaf){
        if (group_dict[[i-1]][j]%in%c(row,col)){
          chf[[j]]=result_combined_2$cumhaz
          time[[j]]=result_combined_2$time
        }
      }
      
      chf_value_dict[[i]]=chf
      time_dict[[i]]=time
      
      #update the group assignment and decide the next combination
      
      group=ifelse(group%in%c(row,col), min(row,col), group)
      #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
      
      for (ii in 1:num_leaf){
        if (dict[ii]==max(row,col)){
          dict[ii]=min(row,col)
        }
      }
      group_dict[[i]]=dict
      
      if (i != num_leaf){
        train_2=cbind(CV_train,group)
        result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
        pvalue=result$p.value
        index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
        row=as.integer(rownames(pvalue)[index[1,1]])
        col=as.integer(colnames(pvalue)[index[1,2]])
        
        result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
      }
    }
  } # end of fitting the trees
  
  # now chf_value_dict is a list with length=num_leaf, each element of the list is still a list with length=num_leaf
  # The jth element of the ith element of chf_value_dict is the chf values for the jth leaf in the tree-like model with num_leaf-i+1 total leaves left
  # Same result for time_dict
  
  test_predict=predict(model2, data=CV_test)
  chf_predict=test_predict$chf

  # test_group=rep(NA,nrow(CV_test))
  # 
  # for (i in 1:nrow(CV_test)) {
  #   for (j in 1:length(leaf)) {
  #     if (all(chf_predict[i,] == leaf[[j]])) {
  #       test_group[i]=reassign_dict[j]
  #     }
  #   }
  # }
  
    # for (j in 1:nrow(CV_test)){
  #   row_time[(step-1)*step_count+j]=CV_test$time[j]
  #   row_event[(step-1)*step_count+j]=CV_test$status[j]
  #   for (i in 1:num_leaf){
  #     value=chf_value_dict[[i]][[test_group[j]]]
  #     time=time_dict[[i]][[test_group[j]]]
  # 
  #     index=length(time) # find the index of the largest time value smaller than t
  #     while(tau<time[index] && index>1){
  #       index=index-1
  #     }
  #     risk_score[[i]][(step-1)*step_count+j]=1-exp(-value[index])
  # 
  #   }
  # 
  # }
  
  # store the risk score for test observations calculated by each tree
  
  for (j in 1:nrow(CV_test)){
    row_time=c(row_time,CV_test$time[j])
    row_event=c(row_event,CV_test$status[j])
    for (i in 1:num_leaf){
      value=chf_value_dict[[i]][[test_group[j]]]
      time=time_dict[[i]][[test_group[j]]]

      index=length(time) # find the index of the largest time value smaller than t
      while(tau<time[index] && index>1){
        index=index-1
      }
      risk_score[[i]]=c(risk_score[[i]],1-exp(-value[index]))

    }
  }
  
}

# Remove the 0 at the beginning of each risk score
for (i in 1:num_leaf){
  risk_score[[i]]=risk_score[[i]][-1]
}
# Now risk_score is a list with length=num_leaf. The ith element of risk_score is the failure probability of each patient predicted using the tree-like model with num_leaf-i+1 leaves

# cv_c_index=rep(0,num_leaf)
# for (i in 1:num_leaf){
#   cv_c_index[i]=cIndex(row_time,row_event,as.vector(risk_score[[i]]))[1]
# }
# # cv_c_index

if (structure==FALSE){
  next
}


fn=function(x){
  result=0
  for (i in 1:num_leaf){
    result=result+x[i]*risk_score[[i]]
  }
  fn=cIndex(row_time,row_event,as.vector(result))[1]
  
  fn
}

heq=function(x){
  h=rep(0,1)
  for (i in 1:num_leaf){
    h[1]=h[1]+x[i]
  }
  h[1]=h[1]-1
  h
}

hin=function(x){
  h=rep(NA,1)
  for (i in 1:num_leaf){
    h[i]=x[i]
  }
  h
}

set.seed(1111)
p0=runif(num_leaf)
ans=constrOptim.nl(par=p0, fn=fn, heq=heq, hin=hin)
ans$par

parameter=ans$par/sum(ans$par)
```

* Access the tree structure info.
```{r}
treeInfo(model2)
reassign_dict
```

* Now fit the model on the full train data
```{r}
# Use the full group

predict2=predict(model2, data=train)
chf_time=predict2$unique.death.times
chf_value=predict2$chf

for (i in 1:nrow(train)) {
  for (j in 1:length(leaf)) {
    if (all(chf_value[i,] == leaf[[j]])) {
      group[i]=reassign_dict[j]
    }
  }
}

chf_value_dict=list(leaf) # a list of lists of chf values
time=list()
for (i in 1:num_leaf){
  time[[i]]=chf_time
}
time_dict=list(time) # a list of lists of time points


test_risk_score=list()
for (i in 1:num_leaf){
  test_risk_score[[i]]=rep(NA,nrow(test))
}

train_set=cbind(train,group)

# Perform the log-rank test
result <- pairwise_survdiff(Surv(time, status)~group, data=train_set)

pvalue=result$p.value
index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
row=as.integer(rownames(pvalue)[index[1,1]])
col=as.integer(colnames(pvalue)[index[1,2]])

result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))

chf_value_combined_2=result_combined_2$cumhaz
chf_time_combined_2=result_combined_2$time

dict=as.vector(1:num_leaf)
group_dict=list(dict)

if (num_leaf>1){
  for (i in 2:(num_leaf)){
    #record the current chf function value and time
    chf=chf_value_dict[[i-1]]
    time=time_dict[[i-1]]
    for (j in 1:num_leaf){
      if (group_dict[[i-1]][j]%in%c(row,col)){
        chf[[j]]=result_combined_2$cumhaz
        time[[j]]=result_combined_2$time
      }
    }
    
    chf_value_dict[[i]]=chf
    time_dict[[i]]=time
    
    #update the group assignment and decide the next combination
    
    group=ifelse(group%in%c(row,col), min(row,col), group)
    #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
    
    for (ii in 1:num_leaf){
      if (dict[ii]==max(row,col)){
        dict[ii]=min(row,col)
      }
    }
    group_dict[[i]]=dict
    
    if (i != num_leaf){
      train_2=cbind(train,group)
      result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
      pvalue=result$p.value
      index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
      row=as.integer(rownames(pvalue)[index[1,1]])
      col=as.integer(colnames(pvalue)[index[1,2]])
      
      result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
    }
  }
} # end of fitting the trees
```

* Draw the survival curve for each leaf in the initial tree
```{r}
#avoiding tail distribution error
tau=600
prob=list()
num_interval=400
terminal=1 # leaf number

for (i in 1:num_leaf){
  prob[[i]]=rep(0,num_interval)
  for (k in 1:num_interval){
    t = tau/num_interval*k
    index=length(time_dict[[i]][[terminal]]) # find the index of the largest time value smaller than t
    while(t<time_dict[[i]][[terminal]][index] && index>1){
      index=index-1
    }
    prob[[i]][k]=exp(-chf_value_dict[[i]][[terminal]][index])
    }
}

result=rep(0,num_interval)
for (i in 1:num_leaf){
  result=result+parameter[i]*prob[[i]]
}

par(mfrow = c(1, 1))  # Set the number of rows and columns for plots
par(plt = c(0.3, 0.6, 0.2, 0.85))  # Set margins for the plot
plot(seq(tau/num_interval,tau,tau/num_interval),result,type="l",xlab="Time", ylab="Survival Probability",ylim=c(0,1),main="Node 5")
```
This shows the correspondence between leaf number in R and leaf number in the ppt
```{r}
treeInfo(model2)
reassign_dict
```
* Now evaluate model performance using the test dataset
```{r}
test_predict=predict(model2, data=test)
chf_predict=test_predict$chf
test_group=rep(NA,nrow(test))

for (i in 1:nrow(test)) {
  for (j in 1:length(leaf)) {
    if (all(chf_predict[i,] == leaf[[j]])) {
      test_group[i]=reassign_dict[j]
    }
  }
}

for (j in 1:nrow(test)){
  for (i in 1:num_leaf){
    value=chf_value_dict[[i]][[test_group[j]]]
    time=time_dict[[i]][[test_group[j]]]
    
    index=length(time) # find the index of the largest time value smaller than t
    while(tau<time[index] && index>1){
      index=index-1
    }
    test_risk_score[[i]][j]=1-exp(-value[index])
    
  }
  
}

test_c_index=rep(0,num_leaf)
for (i in 1:num_leaf){
  test_c_index[i]=cIndex(test$time,test$status,as.vector(test_risk_score[[i]]))[1]
}
result=0
for (i in 1:num_leaf){
  result=result+parameter[i]*test_risk_score[[i]] # calculating the ensemble risk score
}

super_loss=cIndex(test$time,test$status,as.vector(result))[1]
initial_loss=test_c_index[1]

test_predict=predict(model1, data=test)
chf_predict=test_predict$chf
chf_predict_time=test_predict$unique.death.times
test_risk_score2=rep(0,nrow(test))

for (j in 1:nrow(test)){
  index=length(chf_predict_time) # find the index of the largest time value smaller than t
  while(tau<chf_predict_time[index] && index>1){
    index=index-1
  }
  test_risk_score2[j]=1-exp(-chf_predict[j,index])
}

forest_loss=cIndex(test$time,test$status,as.vector(test_risk_score2))[1]

```

```{r}
super_loss # c index of proposed ensemble model
initial_loss # c index of single tree model
forest_loss # c index of random forest model
```
```{r}
leaf_node_dict=rep(0,num_leaf)
for (i in 1:num_leaf){
  obs=leaf_allocation[[i]][1]
  leaf_node_dict[i]=getTerminalNodeIDs(model2,train)[obs]
}
leaf_node_dict # dictionary of leaf number according to the treeInfo function
```
