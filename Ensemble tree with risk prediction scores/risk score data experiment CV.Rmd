---
title: "real data analysis experiment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
library(intsurv)
library(survminer)
library(survival)
library(readr)
library(randomForestSRC)
library(ranger)
library(alabama)
library(dplyr)
```

```{r}
EMC_score=read.csv("./EMC_score.csv")
EI_score=read.csv("./EI_OS_score.csv")
UAMS_score=read.csv("./UAMS_score.csv")
GPI_score=read.csv("./GPI_score.csv")
```

```{r}
merged=merge(EMC_score,EI_score,by="patient")%>%
  rename(EMC=score,EI=OS_score)%>%
  merge(UAMS_score,by="patient")%>%
  rename(UAMS=score)%>%
  merge(GPI_score,by="patient")%>%
  rename(GPI=score)
```

```{r}
merged$EMC=ifelse(merged$EMC>quantile(merged$EMC,0.8),1,0)
merged$UAMS=ifelse(merged$UAMS>quantile(merged$UAMS,0.8),1,0)
merged$GPI=ifelse(merged$GPI>quantile(merged$GPI,0.8),1,0)
merged$EI=ifelse(merged$EI>=quantile(merged$EI,0.8),1,0)
```

```{r}
library(dplyr)
MMRF_CoMMpass_IA21_STAND_ALONE_SURVIVAL=read_tsv("./MMRF_CoMMpass_IA21_STAND_ALONE_SURVIVAL.tsv")%>%
  dplyr::select("ttcos","censos","PUBLIC_ID")%>%
  rename(patient=PUBLIC_ID,time=ttcos,status=censos)
```
```{r}
merged_data01=merge(merged,MMRF_CoMMpass_IA21_STAND_ALONE_SURVIVAL,by="patient")
patient_ID=merged_data01$patient
merged_data01=merged_data01[,-1]
```

```{r}
merged=merge(EMC_score,EI_score,by="patient")%>%
  rename(EMC=score,EI=OS_score)%>%
  merge(UAMS_score,by="patient")%>%
  rename(UAMS=score)%>%
  merge(GPI_score,by="patient")%>%
  rename(GPI=score)
```

```{r}
merged_data=merge(merged,MMRF_CoMMpass_IA21_STAND_ALONE_SURVIVAL,by="patient")
patient_ID=merged_data$patient
merged_data=merged_data[,-1]
```


* Draw the histogram to decide the cut-off point
* Nelson Aalen estimator might make biased prediction at tails
```{r}
forest_loss=rep(0,500)
initial_loss=rep(0,500)
super_loss=rep(0,500)

forest_loss01=rep(0,500)
initial_loss01=rep(0,500)
super_loss01=rep(0,500)

for (seed in 1:500){
  set.seed(seed)
  train_index = sample(nrow(merged), 400, replace = F)
  train = merged_data[train_index,]
  test = merged_data[-train_index,]
  tau=max(merged_data$time)
  
  structure=TRUE
  model1=ranger(Surv(time, status) ~ .,data=train,num.tree=500,mtry=ncol(train)-2,splitrule = "logrank", min.node.size = 5)
  
  set.seed(109) 
  # seed 109, num_leaf=4, min leaf size=13
  # seed 7305, min leaf size=11
  
  # Fit single survival tree to get initial leaf allocation
  model2=ranger(Surv(time, status) ~ .,data=train,num.tree=1,mtry=ncol(train)-2, splitrule = "logrank", min.node.size = 75) 
  predict2=predict(model2, data=train)
  chf_time=predict2$unique.death.times
  chf_value=predict2$chf
  
  leaf <- list() #create a list for the first four CHF curves
  leaf[[1]] <- chf_value[1,]
  leaf_allocation <- list()
  leaf_allocation[[1]] <- c(1)
  group=rep(NA,nrow(train)) #create a dictionary to reflect which group each observation is in
  group[1]=1
  
  #categorize the initial chf function for each leaf
  for (i in 2:nrow(train)) {
    found <- 0
    for (j in 1:length(leaf)) {
      if (all(chf_value[i,] == leaf[[j]])) {
        leaf_allocation[[j]] <- c(leaf_allocation[[j]], i)
        found <- 1
        group[i]=j
      }
    }
    if (found == 0) {
      leaf[[length(leaf) + 1]] <- chf_value[i,]
      leaf_allocation[[length(leaf_allocation) + 1]] <- i
      group[i]=length(leaf_allocation)
    }
  }
  
  
  # We now make sure every leaf has at least 2 observations, otherwise the tree structure might not pertain in 10-fold cross validation. For leaves with 1 or 2 observations, we randomly combine this leaf with another leaf.
  leaf_size=as.vector(table(group))
  single_leaf=as.vector(which(leaf_size<=2))
  normal_leaf=as.vector(which(leaf_size>2))
  
  reassign_dict=as.vector(1:length(leaf))
  for (i in 1:length(single_leaf)){
    new_assignment=sample(normal_leaf,1)
    group[which(group==single_leaf[i])]=new_assignment
    reassign_dict[single_leaf[i]]=new_assignment
  }
  
  # print(min(table(group)))
  # print(table(group))
  
  # change the group from 1 3 4 5 to 1 2 3 4 after combining leaves
  num_leaf=length(table(group))
  loose_group=as.numeric(names(table(group)))
  for (i in 1:length(group)){
    group[i]=which(loose_group==group[i])
  }
  for (i in 1:length(leaf)){
    reassign_dict[i]=which(loose_group==reassign_dict[i])
  }
  # print(table(group))
  
  num_leaf=length(table(group))
  # print(leaf_allocation)
  # print(group)
  
  # keep the first group allocation for CV
  first_group=group
  
  #create overall lists of chf function x and y values
  chf_value_dict=list(leaf) # a list of lists of chf values
  time=list()
  for (i in 1:num_leaf){
    time[[i]]=chf_time
  }
  time_dict=list(time) # a list of lists of time points
  
  # 10-fold cross validation
  if (min(table(group))>=2){ # condition automatically fulfilled from the recombining step
    fold=10
    sampleframe = rep(1:fold, ceiling( nrow(train)/fold ) )
    CV_index=sample(sampleframe,nrow(train) ,  replace=FALSE )
    # CV_index=rep(1:10,nrow(train)/10)
    CV_losses=list()
  }else{
    fold=nrow(train)
    CV_index=1:nrow(train)
    CV_losses=list()
  }
  
  # Store the time, event data for calculating test c index
  row_time=c()
  row_event=c()
  risk_score=list()
  for (i in 1:num_leaf){
    risk_score[[i]]=c(0)
  }
  
  for (step in 1:fold){
    CV_test=train[CV_index==step,]
    CV_train=train[CV_index!=step,]
    group=first_group[CV_index!=step] # if 10-fold, drop 10 elements in group
    test_group=first_group[CV_index==step]
    if (length(table(group))!=num_leaf){
      structure=FALSE
      break
    }
    #For each validation fold, we update the estimator in each leaf using the data from this leaf specifically.
    first_chf=list()
    first_time=list()
    for (i in 1:num_leaf){
      result_combined=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(CV_train,group==i))
      chf=result_combined$cumhaz
      first_chf[[i]]=chf
      time=result_combined$time
      first_time[[i]]=time
    }
    chf_value_dict[[1]]=first_chf
    time_dict[[1]]=first_time
    
    predict2=predict(model2, data=CV_train)
    # chf_time=predict2$unique.death.times
    # chf_value=predict2$chf
    
    train_set=cbind(CV_train,group)
    # Perform the log-rank test
    
    result=tryCatch( # some time only event or only non-event, cannot do pairwise log rank
      expr={
        pairwise_survdiff(Surv(time, status)~group, data=train_set)
      },
      error = function(e) {
        message("There was an error message.") # prints structure of exception
        return(list(NULL))
      }
    )
    
    if (length(result)==1){
      structure=FALSE
      break
    }
    result=pairwise_survdiff(Surv(time, status)~group, data=train_set)
    
    pvalue=result$p.value
    index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
    row=as.integer(rownames(pvalue)[index[1,1]])
    col=as.integer(colnames(pvalue)[index[1,2]]) #row and col are index of the leaves to be combined
    
    result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))
    
    chf_value_combined_2=result_combined_2$cumhaz
    chf_time_combined_2=result_combined_2$time
    
    dict=as.vector(1:num_leaf) # store the process of combining leaves
    group_dict=list(dict)
    
    if (num_leaf>1){
      for (i in 2:(num_leaf)){
        #record the current chf function value and time
        chf=chf_value_dict[[i-1]]
        time=time_dict[[i-1]]
        for (j in 1:num_leaf){
          if (group_dict[[i-1]][j]%in%c(row,col)){
            chf[[j]]=result_combined_2$cumhaz
            time[[j]]=result_combined_2$time
          }
        }
        
        chf_value_dict[[i]]=chf
        time_dict[[i]]=time
        
        #update the group assignment and decide the next combination
        
        group=ifelse(group%in%c(row,col), min(row,col), group)
        #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
        
        for (ii in 1:num_leaf){
          if (dict[ii]==max(row,col)){
            dict[ii]=min(row,col)
          }
        }
        group_dict[[i]]=dict
        
        if (i != num_leaf){
          train_2=cbind(CV_train,group)
          result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
          pvalue=result$p.value
          index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
          row=as.integer(rownames(pvalue)[index[1,1]])
          col=as.integer(colnames(pvalue)[index[1,2]])
          
          result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
        }
      }
    } # end of fitting the trees
    
    # now chf_value_dict is a list with length=num_leaf, each element of the list is still a list with length=num_leaf
    # The jth element of the ith element of chf_value_dict is the chf values for the jth leaf in the tree-like model with num_leaf-i+1 total leaves left
    # Same result for time_dict
    
    test_predict=predict(model2, data=CV_test)
    chf_predict=test_predict$chf
  
    # test_group=rep(NA,nrow(CV_test))
    # 
    # for (i in 1:nrow(CV_test)) {
    #   for (j in 1:length(leaf)) {
    #     if (all(chf_predict[i,] == leaf[[j]])) {
    #       test_group[i]=reassign_dict[j]
    #     }
    #   }
    # }
    
      # for (j in 1:nrow(CV_test)){
    #   row_time[(step-1)*step_count+j]=CV_test$time[j]
    #   row_event[(step-1)*step_count+j]=CV_test$status[j]
    #   for (i in 1:num_leaf){
    #     value=chf_value_dict[[i]][[test_group[j]]]
    #     time=time_dict[[i]][[test_group[j]]]
    # 
    #     index=length(time) # find the index of the largest time value smaller than t
    #     while(tau<time[index] && index>1){
    #       index=index-1
    #     }
    #     risk_score[[i]][(step-1)*step_count+j]=1-exp(-value[index])
    # 
    #   }
    # 
    # }
    
    # store the risk score for test observations calculated by each tree
    
    for (j in 1:nrow(CV_test)){
      row_time=c(row_time,CV_test$time[j])
      row_event=c(row_event,CV_test$status[j])
      for (i in 1:num_leaf){
        value=chf_value_dict[[i]][[test_group[j]]]
        time=time_dict[[i]][[test_group[j]]]
  
        index=length(time) # find the index of the largest time value smaller than t
        while(tau<time[index] && index>1){
          index=index-1
        }
        risk_score[[i]]=c(risk_score[[i]],1-exp(-value[index]))
  
      }
    }
    
  }
  
  # Remove the 0 at the beginning of each risk score
  for (i in 1:num_leaf){
    risk_score[[i]]=risk_score[[i]][-1]
  }
  # Now risk_score is a list with length=num_leaf. The ith element of risk_score is the failure probability of each patient predicted using the tree-like model with num_leaf-i+1 leaves
  
  # cv_c_index=rep(0,num_leaf)
  # for (i in 1:num_leaf){
  #   cv_c_index[i]=cIndex(row_time,row_event,as.vector(risk_score[[i]]))[1]
  # }
  # # cv_c_index
  
  if (structure==FALSE){
    next
  }
  
  
  fn=function(x){
    result=0
    for (i in 1:num_leaf){
      result=result+x[i]*risk_score[[i]]
    }
    fn=cIndex(row_time,row_event,as.vector(result))[1]
    
    fn
  }
  
  heq=function(x){
    h=rep(0,1)
    for (i in 1:num_leaf){
      h[1]=h[1]+x[i]
    }
    h[1]=h[1]-1
    h
  }
  
  hin=function(x){
    h=rep(NA,1)
    for (i in 1:num_leaf){
      h[i]=x[i]
    }
    h
  }
  
  set.seed(1111)
  p0=runif(num_leaf)
  ans=constrOptim.nl(par=p0, fn=fn, heq=heq, hin=hin)
  
  parameter=ans$par/sum(ans$par)
  
  # Use the full group
  
  predict2=predict(model2, data=train)
  chf_time=predict2$unique.death.times
  chf_value=predict2$chf
  
  for (i in 1:nrow(train)) {
    for (j in 1:length(leaf)) {
      if (all(chf_value[i,] == leaf[[j]])) {
        group[i]=reassign_dict[j]
      }
    }
  }
  
  chf_value_dict=list(leaf) # a list of lists of chf values
  time=list()
  for (i in 1:num_leaf){
    time[[i]]=chf_time
  }
  time_dict=list(time) # a list of lists of time points
  
  
  test_risk_score=list()
  for (i in 1:num_leaf){
    test_risk_score[[i]]=rep(NA,nrow(test))
  }
  
  train_set=cbind(train,group)
  
  # Perform the log-rank test
  result <- pairwise_survdiff(Surv(time, status)~group, data=train_set)
  
  pvalue=result$p.value
  index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
  row=as.integer(rownames(pvalue)[index[1,1]])
  col=as.integer(colnames(pvalue)[index[1,2]])
  
  result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))
  
  chf_value_combined_2=result_combined_2$cumhaz
  chf_time_combined_2=result_combined_2$time
  
  dict=as.vector(1:num_leaf)
  group_dict=list(dict)
  
  if (num_leaf>1){
    for (i in 2:(num_leaf)){
      #record the current chf function value and time
      chf=chf_value_dict[[i-1]]
      time=time_dict[[i-1]]
      for (j in 1:num_leaf){
        if (group_dict[[i-1]][j]%in%c(row,col)){
          chf[[j]]=result_combined_2$cumhaz
          time[[j]]=result_combined_2$time
        }
      }
      
      chf_value_dict[[i]]=chf
      time_dict[[i]]=time
      
      #update the group assignment and decide the next combination
      
      group=ifelse(group%in%c(row,col), min(row,col), group)
      #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
      
      for (ii in 1:num_leaf){
        if (dict[ii]==max(row,col)){
          dict[ii]=min(row,col)
        }
      }
      group_dict[[i]]=dict
      
      if (i != num_leaf){
        train_2=cbind(train,group)
        result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
        pvalue=result$p.value
        index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
        row=as.integer(rownames(pvalue)[index[1,1]])
        col=as.integer(colnames(pvalue)[index[1,2]])
        
        result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
      }
    }
  } # end of fitting the trees
  
  # Now evaluate model performance using the test dataset
  test_predict=predict(model2, data=test)
  chf_predict=test_predict$chf
  test_group=rep(NA,nrow(test))
  
  for (i in 1:nrow(test)) {
    for (j in 1:length(leaf)) {
      if (all(chf_predict[i,] == leaf[[j]])) {
        test_group[i]=reassign_dict[j]
      }
    }
  }
  
  for (j in 1:nrow(test)){
    for (i in 1:num_leaf){
      value=chf_value_dict[[i]][[test_group[j]]]
      time=time_dict[[i]][[test_group[j]]]
      
      index=length(time) # find the index of the largest time value smaller than t
      while(tau<time[index] && index>1){
        index=index-1
      }
      test_risk_score[[i]][j]=1-exp(-value[index])
      
    }
    
  }
  
  test_c_index=rep(0,num_leaf)
  for (i in 1:num_leaf){
    test_c_index[i]=cIndex(test$time,test$status,as.vector(test_risk_score[[i]]))[1]
  }
  result=0
  for (i in 1:num_leaf){
    result=result+parameter[i]*test_risk_score[[i]] # calculating the ensemble risk score
  }
  
  super_loss[seed]=cIndex(test$time,test$status,as.vector(result))[1]
  initial_loss[seed]=test_c_index[1]
  
  test_predict=predict(model1, data=test)
  chf_predict=test_predict$chf
  chf_predict_time=test_predict$unique.death.times
  test_risk_score2=rep(0,nrow(test))
  
  for (j in 1:nrow(test)){
    index=length(chf_predict_time) # find the index of the largest time value smaller than t
    while(tau<chf_predict_time[index] && index>1){
      index=index-1
    }
    test_risk_score2[j]=1-exp(-chf_predict[j,index])
  }
  
  forest_loss[seed]=cIndex(test$time,test$status,as.vector(test_risk_score2))[1]
  
  
  


  
  train = merged_data01[train_index,]
  test = merged_data01[-train_index,]
  tau=max(merged_data01$time)
  
  structure=TRUE
  model1=ranger(Surv(time, status) ~ .,data=train,num.tree=500,mtry=ncol(train)-2,splitrule = "logrank", min.node.size = 5)
  
  set.seed(109) 
  # seed 109, num_leaf=4, min leaf size=13
  # seed 7305, min leaf size=11
  
  # Fit single survival tree to get initial leaf allocation
  model2=ranger(Surv(time, status) ~ .,data=train,num.tree=1,mtry=ncol(train)-2, splitrule = "logrank", min.node.size = 75) 
  predict2=predict(model2, data=train)
  chf_time=predict2$unique.death.times
  chf_value=predict2$chf
  
  leaf <- list() #create a list for the first four CHF curves
  leaf[[1]] <- chf_value[1,]
  leaf_allocation <- list()
  leaf_allocation[[1]] <- c(1)
  group=rep(NA,nrow(train)) #create a dictionary to reflect which group each observation is in
  group[1]=1
  
  #categorize the initial chf function for each leaf
  for (i in 2:nrow(train)) {
    found <- 0
    for (j in 1:length(leaf)) {
      if (all(chf_value[i,] == leaf[[j]])) {
        leaf_allocation[[j]] <- c(leaf_allocation[[j]], i)
        found <- 1
        group[i]=j
      }
    }
    if (found == 0) {
      leaf[[length(leaf) + 1]] <- chf_value[i,]
      leaf_allocation[[length(leaf_allocation) + 1]] <- i
      group[i]=length(leaf_allocation)
    }
  }
  
  
  # We now make sure every leaf has at least 2 observations, otherwise the tree structure might not pertain in 10-fold cross validation. For leaves with 1 or 2 observations, we randomly combine this leaf with another leaf.
  leaf_size=as.vector(table(group))
  single_leaf=as.vector(which(leaf_size<=2))
  normal_leaf=as.vector(which(leaf_size>2))
  
  reassign_dict=as.vector(1:length(leaf))
  for (i in 1:length(single_leaf)){
    new_assignment=sample(normal_leaf,1)
    group[which(group==single_leaf[i])]=new_assignment
    reassign_dict[single_leaf[i]]=new_assignment
  }
  
  # print(min(table(group)))
  # print(table(group))
  
  # change the group from 1 3 4 5 to 1 2 3 4 after combining leaves
  num_leaf=length(table(group))
  loose_group=as.numeric(names(table(group)))
  for (i in 1:length(group)){
    group[i]=which(loose_group==group[i])
  }
  for (i in 1:length(leaf)){
    reassign_dict[i]=which(loose_group==reassign_dict[i])
  }
  # print(table(group))
  
  num_leaf=length(table(group))
  # print(leaf_allocation)
  # print(group)
  
  # keep the first group allocation for CV
  first_group=group
  
  #create overall lists of chf function x and y values
  chf_value_dict=list(leaf) # a list of lists of chf values
  time=list()
  for (i in 1:num_leaf){
    time[[i]]=chf_time
  }
  time_dict=list(time) # a list of lists of time points
  
  # 10-fold cross validation
  if (min(table(group))>=2){ # condition automatically fulfilled from the recombining step
    fold=10
    sampleframe = rep(1:fold, ceiling( nrow(train)/fold ) )
    CV_index=sample(sampleframe,nrow(train) ,  replace=FALSE )
    # CV_index=rep(1:10,nrow(train)/10)
    CV_losses=list()
  }else{
    fold=nrow(train)
    CV_index=1:nrow(train)
    CV_losses=list()
  }
  
  # Store the time, event data for calculating test c index
  row_time=c()
  row_event=c()
  risk_score=list()
  for (i in 1:num_leaf){
    risk_score[[i]]=c(0)
  }
  
  for (step in 1:fold){
    CV_test=train[CV_index==step,]
    CV_train=train[CV_index!=step,]
    group=first_group[CV_index!=step] # if 10-fold, drop 10 elements in group
    test_group=first_group[CV_index==step]
    if (length(table(group))!=num_leaf){
      structure=FALSE
      break
    }
    #For each validation fold, we update the estimator in each leaf using the data from this leaf specifically.
    first_chf=list()
    first_time=list()
    for (i in 1:num_leaf){
      result_combined=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(CV_train,group==i))
      chf=result_combined$cumhaz
      first_chf[[i]]=chf
      time=result_combined$time
      first_time[[i]]=time
    }
    chf_value_dict[[1]]=first_chf
    time_dict[[1]]=first_time
    
    predict2=predict(model2, data=CV_train)
    # chf_time=predict2$unique.death.times
    # chf_value=predict2$chf
    
    train_set=cbind(CV_train,group)
    # Perform the log-rank test
    
    result=tryCatch( # some time only event or only non-event, cannot do pairwise log rank
      expr={
        pairwise_survdiff(Surv(time, status)~group, data=train_set)
      },
      error = function(e) {
        message("There was an error message.") # prints structure of exception
        return(list(NULL))
      }
    )
    
    if (length(result)==1){
      structure=FALSE
      break
    }
    result=pairwise_survdiff(Surv(time, status)~group, data=train_set)
    
    pvalue=result$p.value
    index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
    row=as.integer(rownames(pvalue)[index[1,1]])
    col=as.integer(colnames(pvalue)[index[1,2]]) #row and col are index of the leaves to be combined
    
    result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))
    
    chf_value_combined_2=result_combined_2$cumhaz
    chf_time_combined_2=result_combined_2$time
    
    dict=as.vector(1:num_leaf) # store the process of combining leaves
    group_dict=list(dict)
    
    if (num_leaf>1){
      for (i in 2:(num_leaf)){
        #record the current chf function value and time
        chf=chf_value_dict[[i-1]]
        time=time_dict[[i-1]]
        for (j in 1:num_leaf){
          if (group_dict[[i-1]][j]%in%c(row,col)){
            chf[[j]]=result_combined_2$cumhaz
            time[[j]]=result_combined_2$time
          }
        }
        
        chf_value_dict[[i]]=chf
        time_dict[[i]]=time
        
        #update the group assignment and decide the next combination
        
        group=ifelse(group%in%c(row,col), min(row,col), group)
        #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
        
        for (ii in 1:num_leaf){
          if (dict[ii]==max(row,col)){
            dict[ii]=min(row,col)
          }
        }
        group_dict[[i]]=dict
        
        if (i != num_leaf){
          train_2=cbind(CV_train,group)
          result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
          pvalue=result$p.value
          index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
          row=as.integer(rownames(pvalue)[index[1,1]])
          col=as.integer(colnames(pvalue)[index[1,2]])
          
          result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
        }
      }
    } # end of fitting the trees
    
    # now chf_value_dict is a list with length=num_leaf, each element of the list is still a list with length=num_leaf
    # The jth element of the ith element of chf_value_dict is the chf values for the jth leaf in the tree-like model with num_leaf-i+1 total leaves left
    # Same result for time_dict
    
    test_predict=predict(model2, data=CV_test)
    chf_predict=test_predict$chf
  
    # test_group=rep(NA,nrow(CV_test))
    # 
    # for (i in 1:nrow(CV_test)) {
    #   for (j in 1:length(leaf)) {
    #     if (all(chf_predict[i,] == leaf[[j]])) {
    #       test_group[i]=reassign_dict[j]
    #     }
    #   }
    # }
    
      # for (j in 1:nrow(CV_test)){
    #   row_time[(step-1)*step_count+j]=CV_test$time[j]
    #   row_event[(step-1)*step_count+j]=CV_test$status[j]
    #   for (i in 1:num_leaf){
    #     value=chf_value_dict[[i]][[test_group[j]]]
    #     time=time_dict[[i]][[test_group[j]]]
    # 
    #     index=length(time) # find the index of the largest time value smaller than t
    #     while(tau<time[index] && index>1){
    #       index=index-1
    #     }
    #     risk_score[[i]][(step-1)*step_count+j]=1-exp(-value[index])
    # 
    #   }
    # 
    # }
    
    # store the risk score for test observations calculated by each tree
    
    for (j in 1:nrow(CV_test)){
      row_time=c(row_time,CV_test$time[j])
      row_event=c(row_event,CV_test$status[j])
      for (i in 1:num_leaf){
        value=chf_value_dict[[i]][[test_group[j]]]
        time=time_dict[[i]][[test_group[j]]]
  
        index=length(time) # find the index of the largest time value smaller than t
        while(tau<time[index] && index>1){
          index=index-1
        }
        risk_score[[i]]=c(risk_score[[i]],1-exp(-value[index]))
  
      }
    }
    
  }
  
  # Remove the 0 at the beginning of each risk score
  for (i in 1:num_leaf){
    risk_score[[i]]=risk_score[[i]][-1]
  }
  # Now risk_score is a list with length=num_leaf. The ith element of risk_score is the failure probability of each patient predicted using the tree-like model with num_leaf-i+1 leaves
  
  # cv_c_index=rep(0,num_leaf)
  # for (i in 1:num_leaf){
  #   cv_c_index[i]=cIndex(row_time,row_event,as.vector(risk_score[[i]]))[1]
  # }
  # # cv_c_index
  
  if (structure==FALSE){
    next
  }
  
  
  fn=function(x){
    result=0
    for (i in 1:num_leaf){
      result=result+x[i]*risk_score[[i]]
    }
    fn=cIndex(row_time,row_event,as.vector(result))[1]
    
    fn
  }
  
  heq=function(x){
    h=rep(0,1)
    for (i in 1:num_leaf){
      h[1]=h[1]+x[i]
    }
    h[1]=h[1]-1
    h
  }
  
  hin=function(x){
    h=rep(NA,1)
    for (i in 1:num_leaf){
      h[i]=x[i]
    }
    h
  }
  
  set.seed(1111)
  p0=runif(num_leaf)
  ans=constrOptim.nl(par=p0, fn=fn, heq=heq, hin=hin)
  
  parameter=ans$par/sum(ans$par)
  
  # Use the full group
  
  predict2=predict(model2, data=train)
  chf_time=predict2$unique.death.times
  chf_value=predict2$chf
  
  for (i in 1:nrow(train)) {
    for (j in 1:length(leaf)) {
      if (all(chf_value[i,] == leaf[[j]])) {
        group[i]=reassign_dict[j]
      }
    }
  }
  
  chf_value_dict=list(leaf) # a list of lists of chf values
  time=list()
  for (i in 1:num_leaf){
    time[[i]]=chf_time
  }
  time_dict=list(time) # a list of lists of time points
  
  
  test_risk_score=list()
  for (i in 1:num_leaf){
    test_risk_score[[i]]=rep(NA,nrow(test))
  }
  
  train_set=cbind(train,group)
  
  # Perform the log-rank test
  result <- pairwise_survdiff(Surv(time, status)~group, data=train_set)
  
  pvalue=result$p.value
  index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
  row=as.integer(rownames(pvalue)[index[1,1]])
  col=as.integer(colnames(pvalue)[index[1,2]])
  
  result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_set,group%in%c(row,col)))
  
  chf_value_combined_2=result_combined_2$cumhaz
  chf_time_combined_2=result_combined_2$time
  
  dict=as.vector(1:num_leaf)
  group_dict=list(dict)
  
  if (num_leaf>1){
    for (i in 2:(num_leaf)){
      #record the current chf function value and time
      chf=chf_value_dict[[i-1]]
      time=time_dict[[i-1]]
      for (j in 1:num_leaf){
        if (group_dict[[i-1]][j]%in%c(row,col)){
          chf[[j]]=result_combined_2$cumhaz
          time[[j]]=result_combined_2$time
        }
      }
      
      chf_value_dict[[i]]=chf
      time_dict[[i]]=time
      
      #update the group assignment and decide the next combination
      
      group=ifelse(group%in%c(row,col), min(row,col), group)
      #print(paste0("Combine group ",row," and ",col," into group ",min(row,col)))
      
      for (ii in 1:num_leaf){
        if (dict[ii]==max(row,col)){
          dict[ii]=min(row,col)
        }
      }
      group_dict[[i]]=dict
      
      if (i != num_leaf){
        train_2=cbind(train,group)
        result=pairwise_survdiff(Surv(time, status)~group, data=train_2)
        pvalue=result$p.value
        index=which(pvalue == max(pvalue,na.rm=T), arr.ind = TRUE)
        row=as.integer(rownames(pvalue)[index[1,1]])
        col=as.integer(colnames(pvalue)[index[1,2]])
        
        result_combined_2=survfit(Surv(time,status)~1, type = "fleming-harrington",data=subset(train_2,group%in%c(row,col)))
      }
    }
  } # end of fitting the trees
  
  # Now evaluate model performance using the test dataset
  test_predict=predict(model2, data=test)
  chf_predict=test_predict$chf
  test_group=rep(NA,nrow(test))
  
  for (i in 1:nrow(test)) {
    for (j in 1:length(leaf)) {
      if (all(chf_predict[i,] == leaf[[j]])) {
        test_group[i]=reassign_dict[j]
      }
    }
  }
  
  for (j in 1:nrow(test)){
    for (i in 1:num_leaf){
      value=chf_value_dict[[i]][[test_group[j]]]
      time=time_dict[[i]][[test_group[j]]]
      
      index=length(time) # find the index of the largest time value smaller than t
      while(tau<time[index] && index>1){
        index=index-1
      }
      test_risk_score[[i]][j]=1-exp(-value[index])
      
    }
    
  }
  
  test_c_index=rep(0,num_leaf)
  for (i in 1:num_leaf){
    test_c_index[i]=cIndex(test$time,test$status,as.vector(test_risk_score[[i]]))[1]
  }
  result=0
  for (i in 1:num_leaf){
    result=result+parameter[i]*test_risk_score[[i]] # calculating the ensemble risk score
  }
  
  super_loss01[seed]=cIndex(test$time,test$status,as.vector(result))[1]
  initial_loss01[seed]=test_c_index[1]
  
  test_predict=predict(model1, data=test)
  chf_predict=test_predict$chf
  chf_predict_time=test_predict$unique.death.times
  test_risk_score2=rep(0,nrow(test))
  
  for (j in 1:nrow(test)){
    index=length(chf_predict_time) # find the index of the largest time value smaller than t
    while(tau<chf_predict_time[index] && index>1){
      index=index-1
    }
    test_risk_score2[j]=1-exp(-chf_predict[j,index])
  }
  
  forest_loss01[seed]=cIndex(test$time,test$status,as.vector(test_risk_score2))[1]

  print(seed)
}
```

```{r}
summary=cbind(forest_loss,forest_loss01,initial_loss,initial_loss01,super_loss,super_loss01)
par(cex.axis=0.8, mar=c(8, 10, 5, 1))
boxplot(summary,beside=T,horizontal=T,las=1,xlab="C index")
```

```{r}
write.csv(summary,"c index comparison.csv",row.names = F)
```

```{r}
summary=read.csv("./c\ index\ comparison.csv")
summary$initial01_ratio=summary$initial_loss01/summary$initial_loss
summary$super01_ratio=summary$super_loss01/summary$initial_loss
summary$forest01_ratio=summary$forest_loss01/summary$initial_loss
summary$super_ratio=summary$super_loss/summary$initial_loss
summary$forest_ratio=summary$forest_loss/summary$initial_loss
summary_ratio=summary[,7:11]
```

```{r}
par(cex.axis=0.8, mar=c(8, 10, 5, 1))
boxplot(summary_ratio,beside=T,horizontal=T,las=1,xlab="C index ratio over initial tree fit with continuous score")
```


